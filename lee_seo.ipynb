{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78415bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import imblearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve, auc\n",
    "import scipy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2482ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/sliu375/dat490/diabetes.csv\"\n",
    "df = pd.read_csv(data_path, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b1895e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "877b421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compute G-mean\n",
    "def g_mean(y_true, y_pred):\n",
    "    from sklearn.metrics import recall_score\n",
    "    sensitivity = recall_score(y_true, y_pred, pos_label=1)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "    return np.sqrt(sensitivity * specificity)\n",
    "\n",
    "# Helper function to compute AUC-PR\n",
    "def auc_pr(y_true, y_prob):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "# Function to compute IR ratio\n",
    "def compute_ir_ratio(y):\n",
    "    counts = np.bincount(y.astype(int))\n",
    "    if len(counts) < 2:  # Ensure both classes are present\n",
    "        return float('inf') if counts[0] > 0 else 0\n",
    "    majority = max(counts)\n",
    "    minority = min(counts)\n",
    "    return majority / minority if minority > 0 else float('inf')\n",
    "\n",
    "# Fisher Information Matrix (Equation 4)\n",
    "def fisher_information(X, beta, lambda_reg):\n",
    "    probs = 1 / (1 + np.exp(-X @ beta))\n",
    "    W = np.diag(probs * (1 - probs))\n",
    "    I = X.T @ W @ X + lambda_reg * np.eye(X.shape[1])\n",
    "    return I\n",
    "\n",
    "# MSEE computation (Equation 7)\n",
    "def compute_msee(X_j, X_i, beta, lambda_reg, S_X, S_y):\n",
    "    # Update Fisher information with X_i\n",
    "    X_S = np.vstack([S_X, X_i])\n",
    "    I_S_xi = fisher_information(X_S, beta, lambda_reg)\n",
    "    I_inv = la.inv(I_S_xi)\n",
    "    \n",
    "    # Predicted probabilities\n",
    "    pi_j = 1 / (1 + np.exp(-X_j @ beta))\n",
    "    \n",
    "    # Bias term\n",
    "    bias_term = -pi_j * (1 - pi_j) * (X_j @ (lambda_reg * I_inv @ beta))\n",
    "    \n",
    "    # Variance term\n",
    "    var_term = (pi_j * (1 - pi_j))**2 * (X_j @ I_inv @ (I_S_xi - lambda_reg * np.eye(X_S.shape[1])) @ I_inv.T @ X_j)\n",
    "    \n",
    "    return (bias_term**2 + var_term)\n",
    "\n",
    "# Here we are... Main Active Downsampling Algorithm\n",
    "def active_downsampling(X, y, l=2, k=200, lambda_reg=1.0, epsilon=0.1, C_size=10):\n",
    "    # Standardize the features\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_std = np.std(X, axis=0)\n",
    "    X_std[X_std == 0] = 1  # Avoid division by zero\n",
    "    X_scaled = (X - X_mean) / X_std\n",
    "\n",
    "    # (1) Initialize training, pool, and test sets\n",
    "    n_samples = X_scaled.shape[0]\n",
    "    indices = np.arange(n_samples)\n",
    "    \n",
    "    # Ensure balanced initial training set (l instances per class)\n",
    "    pos_indices = indices[y == 1]\n",
    "    neg_indices = indices[y == 0]\n",
    "    if len(pos_indices) < l or len(neg_indices) < l:\n",
    "        raise ValueError(f\"Not enough instances to select {l} per class. Pos: {len(pos_indices)}, Neg: {len(neg_indices)}\")\n",
    "    pos_indices = pos_indices[:l]\n",
    "    neg_indices = neg_indices[:l]\n",
    "    train_indices = np.concatenate([pos_indices, neg_indices])\n",
    "    S_indices = train_indices\n",
    "    SC_indices = np.setdiff1d(indices, S_indices)\n",
    "    \n",
    "    # Test set: Use 20% of remaining data\n",
    "    test_size = int(0.2 * len(SC_indices))\n",
    "    test_indices = SC_indices[:test_size]\n",
    "    SC_indices = SC_indices[test_size:]\n",
    "    \n",
    "    S_X, S_y = X_scaled[S_indices], y[S_indices]\n",
    "    SC_X, SC_y = X_scaled[SC_indices], y[SC_indices]\n",
    "    test_X, test_y = X_scaled[test_indices], y[test_indices]\n",
    "    \n",
    "    # (2). Iterative selection\n",
    "    for n in range(k):\n",
    "        if len(SC_X) < C_size:\n",
    "            print(f\"Pool set too small at iteration {n}. Stopping early.\")\n",
    "            break\n",
    "            \n",
    "        # Calculate cost weights (inversely proportional to class frequencies)\n",
    "        S_pos = np.sum(S_y == 1)\n",
    "        S_neg = np.sum(S_y == 0)\n",
    "        c01 = 1 / S_pos if S_pos > 0 else 1\n",
    "        c10 = 1 / S_neg if S_neg > 0 else 1\n",
    "        sample_weight = np.where(S_y == 1, c01, c10)\n",
    "        \n",
    "        # Estimate parameters (Equation 2) using penalized logistic regression\n",
    "        model = LogisticRegression(penalty='l2', C=1/lambda_reg, fit_intercept=True, solver='lbfgs', max_iter=1000)\n",
    "        model.fit(S_X, S_y, sample_weight=sample_weight)\n",
    "        \n",
    "        # Extract beta (coefficients and intercept)\n",
    "        beta = np.concatenate([model.intercept_, model.coef_[0]])\n",
    "        S_X_with_intercept = np.hstack([np.ones((S_X.shape[0], 1)), S_X])\n",
    "        SC_X_with_intercept = np.hstack([np.ones((SC_X.shape[0], 1)), SC_X])\n",
    "        \n",
    "        # Pre-select candidates (Equation 8)\n",
    "        probs = model.predict_proba(SC_X)[:, 1]\n",
    "        uncertainty = np.abs(probs - (1 - probs))\n",
    "        C_indices = np.argsort(uncertainty)[:min(C_size, len(uncertainty))]\n",
    "        C_X = SC_X[C_indices]\n",
    "        C_X_with_intercept = SC_X_with_intercept[C_indices]\n",
    "        \n",
    "        # Compute average MSEE for each candidate (Equation 9)\n",
    "        avg_msee = []\n",
    "        for i in range(len(C_indices)):\n",
    "            msee = 0\n",
    "            for j in range(len(SC_X)):\n",
    "                msee += compute_msee(SC_X_with_intercept[j], C_X_with_intercept[i], beta, lambda_reg, S_X_with_intercept, S_y)\n",
    "            avg_msee.append(msee / len(SC_X))\n",
    "        \n",
    "        # Select the most informative instance\n",
    "        best_idx = np.argmin(avg_msee)\n",
    "        x_star = C_X[best_idx]\n",
    "        y_star = SC_y[C_indices[best_idx]]\n",
    "        \n",
    "        # Update training and pool sets\n",
    "        S_X = np.vstack([S_X, x_star])\n",
    "        S_y = np.append(S_y, y_star)\n",
    "        SC_X = np.delete(SC_X, C_indices[best_idx], axis=0)\n",
    "        SC_y = np.delete(SC_y, C_indices[best_idx])\n",
    "        SC_X_with_intercept = np.delete(SC_X_with_intercept, C_indices[best_idx], axis=0)\n",
    "    \n",
    "    # Now let's count the distribution of the downsampled training set (S_y)\n",
    "    downsampled_distribution = np.bincount(S_y.astype(int))\n",
    "    print(\"Downsampled class distribution (0 vs 1):\", downsampled_distribution)\n",
    "    print(\"Resampled IR ratio:\", compute_ir_ratio(S_y))\n",
    "    \n",
    "    # Final evaluation on test set\n",
    "    y_pred = model.predict(test_X)\n",
    "    y_prob = model.predict_proba(test_X)[:, 1]\n",
    "    f_measure = f1_score(test_y, y_pred)\n",
    "    g_mean_score = g_mean(test_y, y_pred)\n",
    "    auc_score = roc_auc_score(test_y, y_prob)\n",
    "    auc_pr_score = auc_pr(test_y, y_prob)\n",
    "    \n",
    "    return {\n",
    "        \"F-measure\": f_measure,\n",
    "        \"G-mean\": g_mean_score,\n",
    "        \"AUC\": auc_score,\n",
    "        \"AUC-PR\": auc_pr_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf0eb439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution (0 vs 1): [500 268]\n",
      "IR ratio of original dataset: 1.8656716417910448\n",
      "\n",
      "\n",
      "Downsampled class distribution (0 vs 1): [28 26]\n",
      "Resampled IR ratio: 1.0769230769230769\n",
      "Evaluation results: {'F-measure': 0.5961538461538461, 'G-mean': np.float64(0.6802749433047525), 'AUC': np.float64(0.7877928949357521), 'AUC-PR': np.float64(0.7191333988166677)}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Extract X and y\n",
    "X = df.drop('Outcome', axis=1).values\n",
    "y = df['Outcome'].values\n",
    "\n",
    "# Check original class distribution & IR\n",
    "print(\"Class distribution (0 vs 1):\", np.bincount(y))\n",
    "ir_ratio_original = compute_ir_ratio(y)\n",
    "print(\"IR ratio of original dataset:\", ir_ratio_original)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Run the active downsampling algorithm\n",
    "results = active_downsampling(X, y, l=2, k=50, lambda_reg=1.0, epsilon=0.1, C_size=10)\n",
    "print(\"Evaluation results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
